\input{preamble.tex}

\title{Observability Data Engineering}
\subtitle{A Story About Math, Four Golden Signals, and Business Intelligence\\
~~~~or\\
Finding $\pi$ in Observability}
\institute{DevOps Observability Architect}
\author{Jack Neely\\ jjneely@gmail.com}

%%\date{\today}
\date{October 16, 2023}

%%\renewcommand{\labelenumi}{\alpha{enumi}}
\newcommand{\hcancel}[1]{%
    \tikz[baseline=(tocancel.base)]{%
        \node[inner sep=0pt,outer sep=0pt] (tocancel) {#1};
        \draw[red, very thick] (tocancel.south west) -- (tocancel.north east);
    }%
}%
\newcommand{\icancel}[1]{%
    \tikz[baseline=(tocancel.base)]{%
        \node[inner sep=0pt,outer sep=0pt] (tocancel) {#1};
        \draw[red, very thick] (tocancel.south west) -- (tocancel.north east);
        \draw[red, very thick] (tocancel.south east) -- (tocancel.north west);
    }%
}%

\usepackage[most]{tcolorbox}
\newtcolorbox{quotebox}{
    lower separated=false,
    arc=0pt,boxrule=0pt,leftrule=2pt
}

\begin{document}

%% Introduction, Title
\maketitle

\begin{frame}
    \frametitle{Goals}

Anti-Goals
    \begin{itemize}
        \item Define ``Observability'' or Argue ``Monitoring'' vs ``Observability''
        \item Sell You Things
    \end{itemize}

Actual Goals
    \begin{itemize}
        \item Show the Rabbit Hole
        \item Be Excited about Math and Engineering
        \item Share Techniques I Use Everyday
        \item Observability in the Enterprise
        \item Using the Scientific Method
    \end{itemize}

    Good Observability is the gateway drug to Data Science.  Artificial
    Intelligence is just Data Science on steroids.
\end{frame}

%% In the Before Time Lightning Talk
%% Consultant work
%%\begin{frame}
%%    \frametitle{Monitorama PDX 2019: How to know if something is ``up''}
%%    \begin{tikzpicture}[remember picture,overlay]
%%        %%\node[at=(current page.center)] {
%%        %%    \includegraphics[width=10cm]{img/lightning-2019.png}
%%        %%};
%%    \end{tikzpicture}
%%\end{frame}

\begin{frame}
    \frametitle{As a DevOps Observability Architect...}

    \begin{quotebox}
    \emph{What do I monitor?}
    \end{quotebox}

    Google SRE's \hcancel{Four} Five Golden Signals
    \begin{description}[labelwidth=\widthof{Saturation}]
        \item[Traffic] Counter of Units of Work
        \item[Errors] Counter of Units of Work with Exceptions
        \item[Latency] Timer of the distribution of latencies for each Unit of Work
        \item[Saturation] When Pods be scaled up or down
        \item[Health] Is the thing up?  Does it respond to customers?
    \end{description}
\end{frame}

\begin{frame}
    \frametitle{As a DevOps Observability Architect...}

    The \icancel{Four} Five Golden Signals is knowing before the customers do.

    \begin{quotebox}
        \emph{We need to set alerts for these super special customers.}
    \end{quotebox}

    Well, if we set our Histograms correctly and record maximum values we will
    be able to tell when...

    \begin{quotebox}
        \emph{When a customer calls we need to be able to verify the error
            they encountered.  We'll need a high cardinally solution.}
    \end{quotebox}

    Umm...those aren't metrics.  Where are your traces?

    \begin{quotebox}
        \emph{Jack, we're an Enterprise!}
    \end{quotebox}
\end{frame}

\fullsizegraphic{img/enterprise-d-picard-309.png}

\begin{frame}[standout]
    Traffic

    \small{Why we count things}
\end{frame}

%% Count Units of Work
%% Why Counting monotonoically matters like a network device

\begin{frame}
    \frametitle{Why Counters Work}

    \begin{quotebox}
         Systems based in cumulative monotonic sums are naturally simpler, in
         terms of the cost of adding reliability. When collection fails
         intermittently, gaps in the data are naturally averaged from
         cumulative measurements.
         \tcblower
         \hfill --- OpenTelemetry Data Model Specification
    \end{quotebox}

    \begin{description}[labelwidth=\widthof{Synchronization}]
        \item[Accurate] Incremented in discrete whole numbers.  Never misses an event.
        \item[Synchronization] Primitive that allows for multiple observers.
        \item[Low Overhead] Easy implementation.  No copying or recalling previous values.
        \item[Fundamental] Position at time $t$.
    \end{description}

    %% https://www.researchgate.net/publication/3849082_Monotonic_counters_A_new_mechanism_for_thread_synchronization
\end{frame}

\begin{frame}
    \frametitle{Remembering Physics: First and Second Derivatives}
    \begin{columns}
        \begin{column}{0.33\textwidth}
            \begin{figure}[h!]
                \resizebox{\columnwidth}{!}{\input{position.tex}}
                \caption{Position: \scriptsize\tt{requests\_total}}
            \end{figure}
        \end{column}
        \begin{column}{0.33\textwidth}
            \begin{figure}[h!]
                \resizebox{\columnwidth}{!}{\input{velocity.tex}}
                \caption{Velocity: \scriptsize\tt{rate(requests\_total[5m])}}
            \end{figure}
        \end{column}
        \begin{column}{0.33\textwidth}
            \begin{figure}[h!]
                \resizebox{\columnwidth}{!}{\input{acceleration.tex}}
                \caption{Acceleration: \scriptsize\tt{deriv(requests:rate5m[5m])}}
            \end{figure}
        \end{column}
    \end{columns}
    \note[item]{Spike detection}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Counting Caveats: Riemann Sums}
    \note[item]{How to aggregate Counters}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \resizebox{\columnwidth}{!}{\input{riemann-sum.tex}}
        \end{column}
        \begin{column}{0.5\textwidth}
\begin{lstlisting}
interval: 5m
rules:
- record: labels:http_server_requests:rate5m
  expr: >
    sum by (service, namespace, status) (
      rate(http_server_requests_seconds_count{}[5m])
    )
\end{lstlisting}

Integrate and Build Ratio:
            \begin{lstlisting}
1 - (
  sum_over_time(
    sum without (status) (
      labels:http_server_requests:rate5m{
        status=~"5..", service="..."})[7d:5m]
  ) * 300 /
  sum_over_time(
    sum without (status) (
      labels:http_server_requests:rate5m{
        service="..."})[7d:5m]
  ) * 300
)
            \end{lstlisting}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}[standout]
    Errors

    \small
    Your CPU Metrics are Wrong and I can Prove It
\end{frame}

%% Count Units of Work that fail or create an exception
%% How you CPU metrics are wrong
\begin{frame}[fragile]
    \frametitle{Measuring CPU Usage Over Time}

    How do you measure CPU usage of a process?
    \begin{enumerate}
        \item[a.] Jiffies
        \item[b.] Percentages
        \item[c.] Seconds a Process is in the Running State
        \item[d.] All of the above
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Nyquist-Shannon Sampling Theorem}
    \begin{figure}[!h]
        \centering
        \input{nyquist-shannon.tex}
    \end{figure}
    $$ Scrape Interval > 2f $$
\end{frame}
\begin{frame}
    \frametitle{Nyquist-Shannon Sampling Theorem: Aliasing}
    \begin{figure}[!h]
        \centering
        \input{nyquist-shannon2.tex}
    \end{figure}
    $$ Scrape Interval > 2f $$
\end{frame}

\begin{frame}[standout]
    Latency

    \small
    And Other Non-Normal Distributions
\end{frame}

%% Latency: Timers and Distributions -- Why averages are horrible and
%% Anscombe's Quartet. Understanding Gamma Distributions.

\begin{frame}
    \frametitle{Anscomb's Quartet}
    \begin{columns}
        \begin{column}{0.3\textwidth}
            \begin{center}
                \begin{tabular}{ c c }
                    \multicolumn{2}{c}{\textbf{Summary Statistics}} \\
                    \hline
                    $N$ & $11$ \\
                    $\mu\{x_1..x_n\}$ & $9.0$ \\
                    $\mu\{y_1..y_n\}$ & $7.5$ \\
                    $\sigma\{x_1..x_n\}$ & $3.16$ \\
                    $\sigma\{y_1..y_n\}$ & $1.94$ \\
                    $r^2$ & $0.67$
                \end{tabular}
            \end{center}
        \end{column}
        \begin{column}{0.7\textwidth}
            \begin{figure}[!h]
                \centering
                \input{anscombs.tex}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

% Show overlay of Standard Distribution on top of real latency data
\begin{frame}
    \frametitle{Nonstandard Distributions}
    \begin{figure}[!h]
        \centering
        \input{nonstandard-distribution.tex}
    \end{figure}
\end{frame}
\begin{frame}
    \frametitle{Nonstandard Distributions}
    \begin{figure}[!h]
        \centering
        \input{nonstandard-distribution2.tex}
    \end{figure}
\end{frame}

\begin{frame}
    \frametitle{Standard Distribution Curve Formula}

    {\huge $$ f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} $$ }

    \vskip 1em
    \begin{description}
        \item[$\sigma$] Standard Deviation
        \item[$\mu$] Mean
        \item[$e$] The base of the Natural Logarithm, about $2.71828$
        \item[$\pi$] Pi!
    \end{description}
\end{frame}

\begin{frame}[standout]
    Saturation

    \small
    Are You Saturated Yet?
\end{frame}

%% Saturation: Percentiles and Pipelines -- Visualizing percentiles of data,
%% why we cannot combine percentiles, and the magic of histograms.
\input{pipelines.tex}

\begin{frame}[standout]
    Health

    \small
    Of Your Customers
\end{frame}

%% T-Digests

\begin{frame}
    \frametitle{Mission Impossible}

    \textbf{Goal:} Per Customer Median and Percentiles

    \textbf{Problem:} High Velocity Log/Event Data
    \vskip 0.5cm
    \textbf{Goal:} Summarize Per Customer Data Every 15 Minutes

    \textbf{Problem:} Calculating 7 and 30 Day Percentiles from Summaries

    \vskip 0.5cm
    \centering\Large
    Requirements for both \textbf{Robust} and \textbf{Aggregatable} data.
    %%\tt{\{ $ts$: 2023-06-08T22:15:00, $custId$: 9, $N$: 4, $\mu$: 581, $q(.99)$: 595 \}}
\end{frame}

\input{logs.tex}

\begin{frame}
    \frametitle{The T-Digest Algorithm}

    \begin{columns}
        \begin{column}{0.4\textwidth}

            $$ k(q) = \frac{\delta}{2\pi} \sin^{-1}(2q-1) $$
            ~
            \begin{description}
                \item[$q$] Quantile ($0 - 1$ Inclusive)
                \item[$k$]  Scale Factor
                \item[$\delta$] Compression Constant
                \item[$\pi$] Everybody run!  It's $\pi$ again!
            \end{description}
        \end{column}
        \begin{column}{0.6\textwidth}
            \begin{figure}[!h]
                \centering
                \resizebox{\columnwidth}{!}{\input{tdigest.tex}}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Results 24 Hour $q(.99)$ T-Digest Estimations from 15 Minute Rollups}
    Raw data contained 1,730,745 samples and 913 unique customer IDs.

    \input{final-results-1.tex}
\end{frame}

\begin{frame}
    \frametitle{Using the Scientific Method}
    \begin{center}
        \textbf{Adjust the Hypothesis} 
    \end{center}
    \vskip 1cm
    \begin{block}{Hypothesis}
    Using serialized T-Digests as 15 minute rollups will have better accuracy.
    \end{block}
\end{frame}

\input{logs2.tex}

\begin{frame}
    \frametitle{Results 24 Hour $q(.99)$ T-Digest Estimations from 15 Minute T-Digests}
    99\% of results have an error of less than 100\%.
\begin{tikzpicture}[]
\begin{axis}[
    width=13cm,
    height=7cm,
    axis lines=middle,
    ylabel=Error (1 is 100 Percent),
    xlabel=Quantile,
    domain=0:1,
    ylabel near ticks,
    xlabel near ticks,
]
    \addplot table[x index=0,y index=4,col sep=comma]{errors.csv};
\end{axis}
\end{tikzpicture}
\end{frame}

\begin{frame}
    \frametitle{Experiment 2 Results: Extreme Error Cases}
    \begin{figure}[!h]
        \centering
        \input{extreme.tex}
        \caption{Example of High Error Customer Distribution}
    \end{figure}
\end{frame}

\begin{frame}[standout]
    \small

    Averages Lie

    Use Smart Rollups

    There Are FIVE Golden Signals

    Use Quantiles and Max to Understand Latency Spread

    Use the Scientific Method and Mathematically Model Applications
\end{frame}

\begin{frame}[standout]
    Thank You!
    $$\pi$$

    \small
    Jack Neely
    jjneely@gmail.com

    Podcast: operations.fm
\end{frame}

\appendix

\begin{frame}
    \frametitle{References}

    \begin{itemize}
        \item Enterprise NC-1701-D Image Credit: Paramount
        \item \href{https://sre.google/sre-book/monitoring-distributed-systems/}{\alert{Google SRE: Four Golden Signals}}
        \item \href{https://math.dartmouth.edu/opencalc2/cole/lecture8.pdf}{\alert{Dartmouth: The First and Second Derivatives}}
        \item \href{https://en.wikipedia.org/wiki/Nyquist\%E2\%80\%93Shannon_sampling_theorem}{\alert{Nyquist–Shannon sampling theorem}}
        \item \href{https://github.com/tdunning/t-digest/blob/main/docs/t-digest-paper/histo.pdf}{\alert{Computing Extremely Accurate Quantiles Using t-Digests}}
        \item \href{https://www.researchgate.net/publication/222105754_Sample_Quantiles_in_Statistical_Packages}{\alert{Sample Quantiles in Statistical Packages}}
    \end{itemize}
\end{frame}
\end{document}
